{"cells":[{"cell_type":"code","source":["import json \n","import notebookutils \n","import sempy.fabric as fabric \n","from sempy.fabric.exceptions import FabricHTTPException, WorkspaceNotFoundException \n","\n","def pad_or_truncate_string(input_string, length, pad_char=' '):\n","    # Truncate if the string is longer than the specified length\n","    if len(input_string) > length:\n","        return input_string[:length]\n","    # Pad if the string is shorter than the specified length\n","    return input_string.ljust(length, pad_char)\n","\n","def display_return(data):\n","    table_details = [\n","        {\n","        'tableName': table['tableName'],\n","        'status':  table['status'],\n","        'startDateTime':  table['startDateTime'],\n","        'endDateTime':  table['endDateTime'],\n","        'lastSuccessfulSyncDateTime':  table['lastSuccessfulSyncDateTime'],\n","        'error':  table['error']\n","        }\n","        for table in data\n","        ]\n","    for detail in table_details:\n","        print(f\"Table: {pad_or_truncate_string(detail['tableName'],20)} status: {detail['status']} start: {detail['startDateTime']}  end: {detail['endDateTime']}  Last Update: {detail['lastSuccessfulSyncDateTime']}  error: {detail['error']}  \")\n","    print('')\n","    #print(data)\n","    \n","    return;\n","\n","\n","workspace_id=spark.conf.get(\"trident.workspace.id\")\n","lakehouse_id=spark.conf.get(\"trident.lakehouse.id\")\n","\n","#Instantiate the client\n","client = fabric.FabricRestClient()\n","\n","# This is the SQL endpoint I want to sync with the lakehouse, this needs to be the GUI\n","sqlendpoint = fabric.FabricRestClient().get(f\"/v1/workspaces/{workspace_id}/lakehouses/{lakehouse_id}\").json()['properties']['sqlEndpointProperties']['id']\n","\n","# URI for the call \n","uri = f\"v1/workspaces/{workspace_id}/sqlEndpoints/{sqlendpoint}/refreshMetadata?preview=true\" \n","\n","# This is the action, we want to take \n","payload = {} \n","\n","try:\n","    response = client.post(uri,json= payload, lro_wait = True) \n","    sync_status = json.loads(response.text)\n","    display_return(sync_status)\n","\n","except Exception as e: print(e)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"28d1dc31-e513-4378-9392-02bbeec4152e","normalized_state":"finished","queued_time":"2025-06-04T08:40:42.8115983Z","session_start_time":null,"execution_start_time":"2025-06-04T08:40:42.812824Z","execution_finish_time":"2025-06-04T08:40:45.2460749Z","parent_msg_id":"c566d8b6-f896-4949-8bcc-8e345ee4211a"},"text/plain":"StatementMeta(, 28d1dc31-e513-4378-9392-02bbeec4152e, 4, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Table: dbo.dimension_employ status: NotRun start: 2025-06-04T08:40:44.3673478Z  end: 2025-06-04T08:40:44.5079553Z  Last Update: 2025-06-04T07:57:35.497346Z  error: None  \nTable: dbo.dimension_city   status: NotRun start: 2025-06-04T08:40:44.3673478Z  end: 2025-06-04T08:40:44.5079553Z  Last Update: 2025-06-04T07:57:35.7629737Z  error: None  \nTable: dbo.dimension_custom status: NotRun start: 2025-06-04T08:40:44.3673478Z  end: 2025-06-04T08:40:44.5079553Z  Last Update: 2025-06-04T07:57:36.0285965Z  error: None  \nTable: dbo.fact_sale        status: NotRun start: 2025-06-04T08:40:44.3673478Z  end: 2025-06-04T08:40:44.5079553Z  Last Update: 2025-06-04T07:57:36.3410962Z  error: None  \nTable: dbo.dimension_stock_ status: NotRun start: 2025-06-04T08:40:44.3673478Z  end: 2025-06-04T08:40:44.5079553Z  Last Update: 2025-06-04T07:57:36.5598679Z  error: None  \nTable: dbo.dimension_date   status: NotRun start: 2025-06-04T08:40:44.3673478Z  end: 2025-06-04T08:40:44.5079553Z  Last Update: 2025-06-04T07:57:36.79422Z  error: None  \n\n"]}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"844c0656-c847-4935-a3eb-85aec0efc667"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"f6d19585-99bf-40a8-bfe2-d6ece853538e"}],"default_lakehouse":"f6d19585-99bf-40a8-bfe2-d6ece853538e","default_lakehouse_name":"lakehouse","default_lakehouse_workspace_id":"d62d3af9-da91-4500-ac8b-78cd389e34cd"}}},"nbformat":4,"nbformat_minor":5}