{"cells":[{"cell_type":"code","source":["%pip install adal"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"41a7c13d-69de-49b8-87fe-1135ca991601"},{"cell_type":"code","source":["## Example of using the MD Sync REST API, using Service Prinipal\n","\n","import msal\n","import requests\n","import adal\n","\n"," \n","def get_sqlendpoint(workspaceId, header,lakehouse_name):\n","    \"\"\"\n","    This list the SQL endpoints for the given workspace.\n","    \"\"\"\n","    getsqlendpoint = f'https://api.fabric.microsoft.com/v1/workspaces/{workspaceId}/sqlEndpoints'\n","    # Make the GET request\n","    response = requests.get(url=getsqlendpoint, headers=header)\n","    # Extract the list of SQL endpoints from the response and find the SQl Endoint ID for the specfied lakehouse\n","    # git_status = response.json()\n","    # print(git_status)\n","    get_sqlenpoints=response.json().get('value', [])\n","    for sqlendpoint in get_sqlenpoints:\n","        if sqlendpoint['displayName'].lower() == lakehouse_name.lower():\n","            sqlendpoint_id = sqlendpoint['id']\n","            return(sqlendpoint_id)\n","def refresh_sql_endpoint(sqlendpoint_id, header,workspaceId):\n","    \"\"\"\n","    Calls the SQL Endpoint refresh API for the specified SQL Endpoint ID.\n","    \"\"\"\n","    refresh_url = f'https://api.powerbi.com/v1/workspaces/{workspaceId}/sqlEndpoints/{sqlendpoint_id}/refreshMetadata?preview=true'\n","    print(refresh_url)\n","    # Define the payload for the refresh command\n","    # The payload is a JSON object that specifies the command to refresh the SQL Endpoint\n","    payload = {} \n","    # Make the POST request to refresh the SQL Endpoint\n","    response = requests.post(url=refresh_url, headers=header,json=payload)\n","    if response.status_code == 202:\n","        print(f\"SQL Endpoint with ID '{sqlendpoint_id}' is being refreshed.\")\n","    else:\n","        print(f\"Status Code: {response.status_code}, Response: {response.text}\")\n","        \n","if __name__ == \"__main__\":\n","    #TODO: Replace the below to code to pull from information from Key Vault.\n","    #https://learn.microsoft.com/en-us/azure/key-vault/secrets/quick-create-python?tabs=azure-cli\n","    TENANT_ID = '__add the tenant id__'\n","    CLIENT_ID = '__add the client id__'\n","    CLIENT_SECRET = '__add the client secret__'\n","    workspaceId = '__put_your_workspace_here__'\n","    lakehouse_name='__put_your_lakehouse_here__'\n","    # Azure Resource Manager for your Azure subscription\n","    RESOURCE = 'https://analysis.windows.net/powerbi/api'\n","    # The authority URL\n","    AUTHORITY_URL = f'https://login.microsoftonline.com/{TENANT_ID}'\n","    # The scope for the token\n","    SCOPE = ['https://api.fabric.microsoft.com/.default']\n","\n","    # Create a public client application\n","    app = msal.ConfidentialClientApplication(\n","        client_id=CLIENT_ID,\n","        client_credential=CLIENT_SECRET,\n","        authority=AUTHORITY_URL\n","    )\n","    result = app.acquire_token_for_client(scopes=SCOPE)\n","    if 'access_token' in result:\n","        access_token = result['access_token']\n","    else:\n","        raise Exception(f\"Failed to acquire token: {result.get('error_description')}\")\n","\n","    header = {\n","        'Content-Type': 'application/json',\n","        'Authorization': f'Bearer {access_token}'\n","    }\n","    sqlendpoint_id = get_sqlendpoint(workspaceId, header, lakehouse_name)\n","    refresh_sql_endpoint(sqlendpoint_id, header,workspaceId)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d18bb8b5-a7a1-4b2e-bfb0-7416d519333f"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"f6d19585-99bf-40a8-bfe2-d6ece853538e"}],"default_lakehouse":"f6d19585-99bf-40a8-bfe2-d6ece853538e","default_lakehouse_name":"lakehouse","default_lakehouse_workspace_id":"d62d3af9-da91-4500-ac8b-78cd389e34cd"}}},"nbformat":4,"nbformat_minor":5}